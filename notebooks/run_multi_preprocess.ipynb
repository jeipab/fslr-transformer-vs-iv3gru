{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Process Video Preprocessing\n",
        "\n",
        "This notebook demonstrates how to run the optimized multi-process preprocessing script with optimal settings for your hardware configuration.\n",
        "\n",
        "## Hardware Configuration:\n",
        "- **GPU**: RTX 3060, 12 GB VRAM\n",
        "- **CPU**: Xeon E5-2683 v4 (16 cores / 32 threads)\n",
        "- **RAM**: 32 GB\n",
        "- **Disk**: NVMe (~1.3 GB/s)\n",
        "\n",
        "## Expected Performance:\n",
        "- **30-50x speedup** compared to sequential processing\n",
        "- **Processing time**: Days → 2-4 hours for ~2000 videos\n",
        "- **GPU utilization**: Batched InceptionV3 keeps GPU busy\n",
        "- **CPU utilization**: MediaPipe distributed across cores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration\n",
        "\n",
        "**Note**: This notebook automatically suppresses verbose logging from MediaPipe and TensorFlow to provide cleaner output. You'll only see the essential progress information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# Suppress verbose logging from MediaPipe and TensorFlow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow INFO, WARNING, ERROR logs\n",
        "os.environ['MP_VERBOSE'] = '0'  # Suppress MediaPipe verbose output\n",
        "os.environ['GLOG_minloglevel'] = '3'  # Suppress Google logging (used by MediaPipe)\n",
        "\n",
        "# Suppress Python warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(\"✅ Verbose logging suppressed for cleaner output\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration Parameters\n",
        "\n",
        "Configure the preprocessing parameters for optimal performance on your hardware.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION - Modify these paths and parameters as needed\n",
        "# =============================================================================\n",
        "\n",
        "# Input and output paths\n",
        "VIDEO_DIR = \"../data/raw\"  # Directory containing input videos\n",
        "OUTPUT_DIR = \"../data/processed\"  # Directory for processed output\n",
        "LABELS_CSV = \"../data/processed/labels.csv\"  # Path to labels CSV\n",
        "\n",
        "# Performance settings (optimized for your hardware)\n",
        "WORKERS = 10  # Number of parallel workers (optimal for 16-core CPU)\n",
        "BATCH_SIZE = 64  # Batch size for InceptionV3 GPU inference\n",
        "TARGET_FPS = 15  # Target frames per second (recommended for speed)\n",
        "\n",
        "# Processing options\n",
        "WRITE_KEYPOINTS = True  # Extract MediaPipe keypoints\n",
        "WRITE_IV3_FEATURES = True  # Extract InceptionV3 features\n",
        "DISABLE_PARQUET = True  # Disable parquet output for faster I/O (recommended for batch processing)\n",
        "\n",
        "# Labeling options\n",
        "GLOSS_ID = 1  # Gloss ID for labeling\n",
        "CAT_ID = 1  # Category ID for labeling\n",
        "APPEND_LABELS = False  # Append to existing labels CSV\n",
        "\n",
        "# Occlusion detection\n",
        "ENABLE_OCCLUSION = True  # Enable occlusion detection\n",
        "OCC_VIS_THRESH = 0.6  # Frame visible fraction threshold\n",
        "OCC_FRAME_PROP = 0.4  # Clip occluded if proportion >= this\n",
        "OCC_MIN_RUN = 15  # Clip occluded if run length >= this\n",
        "\n",
        "# MediaPipe settings\n",
        "OUT_SIZE = 256  # Output image size for keypoint extraction\n",
        "CONF_THRESH = 0.5  # Confidence threshold for keypoints\n",
        "MAX_GAP = 5  # Maximum gap for interpolation\n",
        "\n",
        "print(\"Configuration loaded successfully!\")\n",
        "print(f\"Video directory: {VIDEO_DIR}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"Workers: {WORKERS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Target FPS: {TARGET_FPS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Validate Input Directory\n",
        "\n",
        "Check that the video directory exists and count the number of video files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_videos(directory):\n",
        "    \"\"\"Count video files in directory.\"\"\"\n",
        "    video_extensions = {'.mp4', '.mov', '.avi', '.mkv'}\n",
        "    count = 0\n",
        "    video_files = []\n",
        "    \n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in video_extensions:\n",
        "                count += 1\n",
        "                video_files.append(os.path.join(root, file))\n",
        "    \n",
        "    return count, video_files\n",
        "\n",
        "# Check if video directory exists\n",
        "if not os.path.exists(VIDEO_DIR):\n",
        "    print(f\"❌ ERROR: Video directory '{VIDEO_DIR}' does not exist!\")\n",
        "    print(\"Please update the VIDEO_DIR variable with the correct path.\")\n",
        "else:\n",
        "    video_count, video_files = count_videos(VIDEO_DIR)\n",
        "    print(f\"✅ Video directory found: {VIDEO_DIR}\")\n",
        "    print(f\"📹 Found {video_count} video files\")\n",
        "    \n",
        "    if video_count > 0:\n",
        "        print(\"\\nFirst 5 video files:\")\n",
        "        for i, video in enumerate(video_files[:5]):\n",
        "            print(f\"  {i+1}. {os.path.basename(video)}\")\n",
        "        if video_count > 5:\n",
        "            print(f\"  ... and {video_count - 5} more\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Output Directory\n",
        "\n",
        "Ensure the output directory exists and is ready for processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"✅ Output directory ready: {OUTPUT_DIR}\")\n",
        "\n",
        "# Check available disk space (approximate)\n",
        "import shutil\n",
        "total, used, free = shutil.disk_usage(OUTPUT_DIR)\n",
        "free_gb = free // (1024**3)\n",
        "print(f\"💾 Available disk space: {free_gb} GB\")\n",
        "\n",
        "# Estimate required space (rough calculation)\n",
        "if 'video_count' in locals() and video_count > 0:\n",
        "    # Rough estimate: ~50MB per video for keypoints + IV3 features\n",
        "    estimated_space_mb = video_count * 50\n",
        "    estimated_space_gb = estimated_space_mb / 1024\n",
        "    print(f\"📊 Estimated space needed: {estimated_space_gb:.1f} GB\")\n",
        "    \n",
        "    if free_gb < estimated_space_gb:\n",
        "        print(f\"⚠️  WARNING: May not have enough disk space!\")\n",
        "    else:\n",
        "        print(f\"✅ Sufficient disk space available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build Command and Validate Parameters\n",
        "\n",
        "Build the multi-process preprocessing command with all required parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_preprocessing_command():\n",
        "    \"\"\"Build the multi-process preprocessing command.\"\"\"\n",
        "    cmd = [\n",
        "        sys.executable, \"../preprocessing/multi_preprocess.py\",\n",
        "        VIDEO_DIR,\n",
        "        OUTPUT_DIR,\n",
        "        \"--workers\", str(WORKERS),\n",
        "        \"--batch-size\", str(BATCH_SIZE),\n",
        "        \"--target-fps\", str(TARGET_FPS),\n",
        "        \"--out-size\", str(OUT_SIZE),\n",
        "        \"--conf-thresh\", str(CONF_THRESH),\n",
        "        \"--max-gap\", str(MAX_GAP)\n",
        "    ]\n",
        "    \n",
        "    # Add processing options\n",
        "    if WRITE_KEYPOINTS:\n",
        "        cmd.append(\"--write-keypoints\")\n",
        "    if WRITE_IV3_FEATURES:\n",
        "        cmd.append(\"--write-iv3-features\")\n",
        "    if DISABLE_PARQUET:\n",
        "        cmd.append(\"--disable-parquet\")\n",
        "    \n",
        "    # Add labeling options\n",
        "    if GLOSS_ID is not None:\n",
        "        cmd.extend([\"--gloss-id\", str(GLOSS_ID)])\n",
        "    if CAT_ID is not None:\n",
        "        cmd.extend([\"--cat-id\", str(CAT_ID)])\n",
        "    if LABELS_CSV is not None:\n",
        "        cmd.extend([\"--labels-csv\", LABELS_CSV])\n",
        "    if APPEND_LABELS:\n",
        "        cmd.append(\"--append\")\n",
        "    \n",
        "    # Add occlusion detection\n",
        "    if ENABLE_OCCLUSION:\n",
        "        cmd.append(\"--occ-enable\")\n",
        "        cmd.extend([\"--occ-vis-thresh\", str(OCC_VIS_THRESH)])\n",
        "        cmd.extend([\"--occ-frame-prop\", str(OCC_FRAME_PROP)])\n",
        "        cmd.extend([\"--occ-min-run\", str(OCC_MIN_RUN)])\n",
        "    \n",
        "    return cmd\n",
        "\n",
        "# Build command\n",
        "command = build_preprocessing_command()\n",
        "\n",
        "print(\"🔧 Multi-process preprocessing command:\")\n",
        "print(\"\\n\".join([f\"  {part}\" for part in command]))\n",
        "\n",
        "print(\"\\n📋 Parameter summary:\")\n",
        "print(f\"  • Workers: {WORKERS}\")\n",
        "print(f\"  • Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  • Target FPS: {TARGET_FPS}\")\n",
        "print(f\"  • Write keypoints: {WRITE_KEYPOINTS}\")\n",
        "print(f\"  • Write IV3 features: {WRITE_IV3_FEATURES}\")\n",
        "print(f\"  • Disable parquet: {DISABLE_PARQUET}\")\n",
        "print(f\"  • Enable occlusion: {ENABLE_OCCLUSION}\")\n",
        "print(f\"  • Gloss ID: {GLOSS_ID}\")\n",
        "print(f\"  • Category ID: {CAT_ID}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Multi-Process Preprocessing\n",
        "\n",
        "Execute the preprocessing with progress monitoring and error handling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_preprocessing():\n",
        "    \"\"\"Run the multi-process preprocessing.\"\"\"\n",
        "    print(\"🚀 Starting multi-process preprocessing...\")\n",
        "    print(f\"⏰ Start time: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Run the command with stderr redirected to suppress warnings\n",
        "        result = subprocess.run(\n",
        "            command,\n",
        "            check=True,\n",
        "            capture_output=False,  # Show output in real-time\n",
        "            text=True,\n",
        "            stderr=subprocess.DEVNULL  # Suppress stderr warnings\n",
        "        )\n",
        "        \n",
        "        end_time = time.time()\n",
        "        total_time = end_time - start_time\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ Preprocessing completed successfully!\")\n",
        "        print(f\"⏰ End time: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"⏱️  Total time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "        \n",
        "        if 'video_count' in locals() and video_count > 0:\n",
        "            print(f\"📊 Average time per video: {total_time/video_count:.2f} seconds\")\n",
        "            print(f\"📈 Videos per hour: {video_count * 3600 / total_time:.1f}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        end_time = time.time()\n",
        "        total_time = end_time - start_time\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"❌ Preprocessing failed with error code: {e.returncode}\")\n",
        "        print(f\"⏱️  Time before failure: {total_time:.2f} seconds\")\n",
        "        return False\n",
        "        \n",
        "    except KeyboardInterrupt:\n",
        "        end_time = time.time()\n",
        "        total_time = end_time - start_time\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"⚠️  Preprocessing interrupted by user\")\n",
        "        print(f\"⏱️  Time before interruption: {total_time:.2f} seconds\")\n",
        "        return False\n",
        "\n",
        "# Run preprocessing\n",
        "success = run_preprocessing()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Verify Results\n",
        "\n",
        "Check the output directory and verify that files were processed correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def verify_results():\n",
        "    \"\"\"Verify the preprocessing results.\"\"\"\n",
        "    print(\"🔍 Verifying preprocessing results...\")\n",
        "    \n",
        "    # Count processed files\n",
        "    npz_files = list(Path(OUTPUT_DIR).glob(\"*.npz\"))\n",
        "    parquet_files = list(Path(OUTPUT_DIR).glob(\"*.parquet\"))\n",
        "    \n",
        "    print(f\"\\n📁 Output directory: {OUTPUT_DIR}\")\n",
        "    print(f\"📄 NPZ files: {len(npz_files)}\")\n",
        "    print(f\"📄 Parquet files: {len(parquet_files)}\")\n",
        "    \n",
        "    # Check labels CSV if it should exist\n",
        "    if LABELS_CSV and os.path.exists(LABELS_CSV):\n",
        "        try:\n",
        "            labels_df = pd.read_csv(LABELS_CSV)\n",
        "            print(f\"📋 Labels CSV: {len(labels_df)} entries\")\n",
        "            print(f\"   Columns: {list(labels_df.columns)}\")\n",
        "            \n",
        "            if 'occluded' in labels_df.columns:\n",
        "                occluded_count = labels_df['occluded'].sum()\n",
        "                print(f\"   Occluded videos: {occluded_count}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Could not read labels CSV: {e}\")\n",
        "    \n",
        "    # Show sample files\n",
        "    if npz_files:\n",
        "        print(f\"\\n📄 Sample processed files:\")\n",
        "        for i, npz_file in enumerate(npz_files[:5]):\n",
        "            file_size = npz_file.stat().st_size / (1024 * 1024)  # MB\n",
        "            print(f\"   {i+1}. {npz_file.name} ({file_size:.1f} MB)\")\n",
        "        if len(npz_files) > 5:\n",
        "            print(f\"   ... and {len(npz_files) - 5} more\")\n",
        "    \n",
        "    # Check for errors\n",
        "    if len(npz_files) == 0:\n",
        "        print(\"❌ No NPZ files found! Check for errors above.\")\n",
        "        return False\n",
        "    \n",
        "    print(\"\\n✅ Verification complete!\")\n",
        "    return True\n",
        "\n",
        "if success:\n",
        "    verify_results()\n",
        "else:\n",
        "    print(\"❌ Skipping verification due to preprocessing failure.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Performance Summary\n",
        "\n",
        "Display a summary of the preprocessing performance and next steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_performance_summary():\n",
        "    \"\"\"Print performance summary and next steps.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📊 PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    if success:\n",
        "        print(\"✅ Status: SUCCESS\")\n",
        "        print(f\"📁 Output directory: {OUTPUT_DIR}\")\n",
        "        print(f\"⚙️  Configuration used:\")\n",
        "        print(f\"   • Workers: {WORKERS}\")\n",
        "        print(f\"   • Batch size: {BATCH_SIZE}\")\n",
        "        print(f\"   • Target FPS: {TARGET_FPS}\")\n",
        "        print(f\"   • Keypoints: {WRITE_KEYPOINTS}\")\n",
        "        print(f\"   • IV3 features: {WRITE_IV3_FEATURES}\")\n",
        "        print(f\"   • Parquet disabled: {DISABLE_PARQUET}\")\n",
        "        \n",
        "        print(\"\\n🚀 Next steps:\")\n",
        "        print(\"1. Use data_split.py to organize files into train/val splits\")\n",
        "        print(\"2. Start training your models\")\n",
        "        print(\"3. Use the Streamlit app to visualize results\")\n",
        "        \n",
        "        if LABELS_CSV and os.path.exists(LABELS_CSV):\n",
        "            print(f\"\\n📋 Labels CSV created: {LABELS_CSV}\")\n",
        "            print(\"   Use this for data splitting and training\")\n",
        "    else:\n",
        "        print(\"❌ Status: FAILED\")\n",
        "        print(\"\\n🔧 Troubleshooting:\")\n",
        "        print(\"1. Check error messages above\")\n",
        "        print(\"2. Verify video directory path\")\n",
        "        print(\"3. Ensure sufficient disk space\")\n",
        "        print(\"4. Check GPU memory usage\")\n",
        "        print(\"5. Try reducing batch size or workers\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "print_performance_summary()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
